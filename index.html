<!DOCTYPE html>
<html>
<head>
    <title>ONNX Runtime JavaScript Example with Caching and Audio Queue</title>
    <meta http-equiv="Cross-Origin-Opener-Policy" content="same-origin">
    <meta http-equiv="Cross-Origin-Embedder-Policy" content="require-corp">
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.all.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/npyjs"></script>
    <script src="https://unpkg.com/wasm-feature-detect/dist/umd/index.js"></script>
</head>
<body>
    <button id="load">Load and Run Model</button>
    <script>
        const modelUrls = {
            diffusion: 'https://media.githubusercontent.com/media/mdl262/RainLDM/main/distilled_q.onnx',
            decoder: 'https://media.githubusercontent.com/media/mdl262/RainLDM/main/decoder_q_gpu.onnx'
        };
        let diffusionSession, decoderSession;
        const audioQueue = [];
        let isInferenceRunning = false;
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();

        document.querySelector('#load').addEventListener('click', runModel);

        async function fetchAndCacheModel(url) {
            const cache = await caches.open('model-cache');
            const cachedResponse = await cache.match(url);

            if (cachedResponse) {
                console.log(`Loaded model from cache: ${url}`);
                return cachedResponse.arrayBuffer();
            } else {
                console.log(`Fetching model from network: ${url}`);
                const response = await fetch(url);
                cache.put(url, response.clone());  // Cache for future use
                return response.arrayBuffer();
            }
        }

        async function loadModel(url) {
            const modelBuffer = await fetchAndCacheModel(url);
            return new Uint8Array(modelBuffer);
        }

        async function initializeSessions() {
            const sessionOptions = {
                executionProviders: [
                    { name: 'webnn', deviceType: 'gpu', powerPreference: "high-performance" },
                    "wasm"
                ],
            };

            // Load models from cache or network
            const diffusionModelBuffer = await loadModel(modelUrls.diffusion);
            const decoderModelBuffer = await loadModel(modelUrls.decoder);

            // Initialize ONNX sessions with model buffers
            diffusionSession = await ort.InferenceSession.create(diffusionModelBuffer, sessionOptions);
            decoderSession = await ort.InferenceSession.create(decoderModelBuffer, sessionOptions);

            console.log("Models loaded and sessions initialized.");
        }

        async function runModel() {
            if (isInferenceRunning) {
                console.log("Inference already running, skipping...");
                return;
            }

            try {
                isInferenceRunning = true;
                await initializeSessions();
                const inputShape = [1, 1024, 1024];

                let playbackStart = false;

                // Call models and fill the queue continuously
                while (true) {
                    await waitForSpaceInQueue()
                    console.log("Running diffusion model...");
                    let diffusionFeeds = { noise: createRandomTensor(inputShape) };
                    
                    let diffusionOutput = await diffusionSession.run(diffusionFeeds);

                    console.log("Running decoder model...");
                    let decoderFeed = { z_quantized: diffusionOutput.z };
                    let decoderOutput = await decoderSession.run(decoderFeed);

                    let audioData = new Float32Array(decoderOutput.s.data);
                    if (audioData.length > 0) {
                        console.log("Pushing audio data to queue...");
                        await pushAudioToQueue(audioData);

                    } else {
                        console.error("Error: Audio data shape is invalid.");
                    }

                    if (!playbackStart) {
                        playNextInQueue();
                        playbackStart = true;
                    }
                }

                console.log("Queue has 5 items, starting audio playback.");
                //playNextInQueue();  // Start playing the audio once we have 5 items in the queue

            } catch (e) {
                console.error("Inference failed:", e);
            } finally {
                isInferenceRunning = false;
            }
        }

        // Gaussian random generator for random tensor data
        function gaussianRandom() {
            let u = Math.random(), v = Math.random();
            const mag = Math.sqrt(-2.0 * Math.log(u));
            return mag * Math.cos(2.0 * Math.PI * v);
        }

        // Create random tensor data with specified shape
        function createRandomTensor(shape) {
            const size = shape.reduce((a, b) => a * b);
            const randomData = new Float32Array(size).map(() => gaussianRandom());
            return new ort.Tensor('float32', randomData, shape);
        }

        async function pushAudioToQueue(audioData) {
            console.log(`Audio queue length: ${audioQueue.length}`);
            if (audioQueue.length >= 5) {
                console.log("Waiting for space in audio queue...");
                await waitForSpaceInQueue();
            }
            audioQueue.push(audioData);
            console.log("Audio data pushed to queue. Queue length now:", audioQueue.length);
        }

        async function waitForSpaceInQueue() {
            return new Promise(resolve => {
                const interval = setInterval(() => {
                    if (audioQueue.length < 5) {
                        clearInterval(interval);
                        resolve();
                    }
                }, 100); // Check every 100 ms
            });
        }

        function playNextInQueue() {
            if (audioQueue.length === 0) return;

            const audioData = audioQueue.shift();
            console.log("Playing audio from queue. Remaining items:", audioQueue.length);

            const buffer = audioContext.createBuffer(1, audioData.length, audioContext.sampleRate);
            buffer.copyToChannel(audioData, 0);

            const source = audioContext.createBufferSource();
            source.buffer = buffer;
            source.connect(audioContext.destination);
            source.onended = () => {
                console.log("Audio finished playing.");
                if (audioQueue.length > 0) {
                    playNextInQueue();
                }
            };
            source.start();
        }
    </script>
</body>
</html>
